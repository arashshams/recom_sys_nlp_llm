{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8699e24f-9d71-4fd2-aeb3-6c8bfb6c9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f291bb-2546-4c17-91b1-03c034a657cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Data Description<a name=\"2\"></a>\n",
    "\n",
    "This project leverages a comprehensive dataset obtained from Kaggle, available at the following link: https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset/data. The dataset encompasses several components, including information about businesses, user, reviews, and other related data. For this analysis, we utilized the business and reviews subsets.\n",
    "\n",
    "After merging the two datasets, we obtained a dataset containing 6,990,280 rows and 21 columns. To focus on a specific subset, we filtered the data to include only restaurants, resulting in 3,773,971 observations. Further refinement was applied by filtering for users and businesses with significant interactions, specifically selecting those with at least 100 reviews for users and 500 reviews for businesses. The final dataset contains 51,618 observations, representing 1,408 unique users and 1,227 unique businesses.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0bf2b88-8b8c-47db-a13f-ce1ac7b81217",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_business = pd.read_json(\"data/yelp/yelp_academic_dataset_business.json\", lines=True)\n",
    "yelp_reviews = pd.read_json(\"data/yelp/yelp_academic_dataset_review.json\", lines = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b62995-63fd-4b6d-b920-4a08c7168cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ByAppointmentOnly': 'True'}</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>MO</td>\n",
       "      <td>63123</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Target</td>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85711</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BikeParking': 'True', 'BusinessAcceptsCredit...</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>{'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'False', 'OutdoorSeati...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>101 Walnut St</td>\n",
       "      <td>Green Lane</td>\n",
       "      <td>PA</td>\n",
       "      <td>18054</td>\n",
       "      <td>40.338183</td>\n",
       "      <td>-75.471659</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Wheelc...</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "      <td>{'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
       "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
       "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
       "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
       "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
       "\n",
       "                           address           city state postal_code  \\\n",
       "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
       "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
       "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
       "3                      935 Race St   Philadelphia    PA       19107   \n",
       "4                    101 Walnut St     Green Lane    PA       18054   \n",
       "\n",
       "    latitude   longitude  stars  review_count  is_open  \\\n",
       "0  34.426679 -119.711197    5.0             7        0   \n",
       "1  38.551126  -90.335695    3.0            15        1   \n",
       "2  32.223236 -110.880452    3.5            22        0   \n",
       "3  39.955505  -75.155564    4.0            80        1   \n",
       "4  40.338183  -75.471659    4.5            13        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                      {'ByAppointmentOnly': 'True'}   \n",
       "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
       "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
       "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
       "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
       "2  Department Stores, Shopping, Fashion, Home & G...   \n",
       "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "4                          Brewpubs, Breweries, Food   \n",
       "\n",
       "                                               hours  \n",
       "0                                               None  \n",
       "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
       "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
       "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
       "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2665dc-165e-4f1b-8537-c584edb5605c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text                date  \n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
       "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n",
       "2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03  \n",
       "4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb00bea2-ad52-4a5c-b2bd-bc1a57dec25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>...</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "      <td>9vwYDBVI3ymdqcyJ5WW2Tg</td>\n",
       "      <td>e0imecnX_9MtLnS2rUZM-A</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I've had acupuncture treatments with Abby over...</td>\n",
       "      <td>2012-05-02 18:07:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "      <td>OXgg1LdxHDv3CBU5-xi2lA</td>\n",
       "      <td>_Q0fdLVoTnlNkEypUvNkHA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abby is an amazing practitioner. In a treatmen...</td>\n",
       "      <td>2013-03-01 06:11:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "      <td>DG64cjud9cWB4fANskVxSw</td>\n",
       "      <td>ycUooVIDWPgXPf6niW-FWQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I went to see Abby for some digestive issues. ...</td>\n",
       "      <td>2013-01-17 00:05:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "      <td>hzvRRb40oPttxAdyr7kfow</td>\n",
       "      <td>CiwVvb7jWijWB5jkmatzKA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Abby helped me with some longstanding issues, ...</td>\n",
       "      <td>2015-03-16 03:43:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "      <td>xUkBPk-QfcW4i3MRU5TeXw</td>\n",
       "      <td>QkCbMKBktkrkOFJugHvY6w</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Recently, I referred a patient of mine with mu...</td>\n",
       "      <td>2013-03-05 18:45:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name                 address  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ  1616 Chapala St, Ste 2   \n",
       "1  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ  1616 Chapala St, Ste 2   \n",
       "2  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ  1616 Chapala St, Ste 2   \n",
       "3  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ  1616 Chapala St, Ste 2   \n",
       "4  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ  1616 Chapala St, Ste 2   \n",
       "\n",
       "            city state postal_code   latitude   longitude  review_count  \\\n",
       "0  Santa Barbara    CA       93101  34.426679 -119.711197             7   \n",
       "1  Santa Barbara    CA       93101  34.426679 -119.711197             7   \n",
       "2  Santa Barbara    CA       93101  34.426679 -119.711197             7   \n",
       "3  Santa Barbara    CA       93101  34.426679 -119.711197             7   \n",
       "4  Santa Barbara    CA       93101  34.426679 -119.711197             7   \n",
       "\n",
       "   is_open  ...                                         categories hours  \\\n",
       "0        0  ...  Doctors, Traditional Chinese Medicine, Naturop...  None   \n",
       "1        0  ...  Doctors, Traditional Chinese Medicine, Naturop...  None   \n",
       "2        0  ...  Doctors, Traditional Chinese Medicine, Naturop...  None   \n",
       "3        0  ...  Doctors, Traditional Chinese Medicine, Naturop...  None   \n",
       "4        0  ...  Doctors, Traditional Chinese Medicine, Naturop...  None   \n",
       "\n",
       "                review_id                 user_id stars  useful  funny  cool  \\\n",
       "0  9vwYDBVI3ymdqcyJ5WW2Tg  e0imecnX_9MtLnS2rUZM-A     5       3      2     1   \n",
       "1  OXgg1LdxHDv3CBU5-xi2lA  _Q0fdLVoTnlNkEypUvNkHA     5       1      0     0   \n",
       "2  DG64cjud9cWB4fANskVxSw  ycUooVIDWPgXPf6niW-FWQ     4       2      0     0   \n",
       "3  hzvRRb40oPttxAdyr7kfow  CiwVvb7jWijWB5jkmatzKA     5       0      1     0   \n",
       "4  xUkBPk-QfcW4i3MRU5TeXw  QkCbMKBktkrkOFJugHvY6w     5       0      0     0   \n",
       "\n",
       "                                                text                date  \n",
       "0  I've had acupuncture treatments with Abby over... 2012-05-02 18:07:38  \n",
       "1  Abby is an amazing practitioner. In a treatmen... 2013-03-01 06:11:05  \n",
       "2  I went to see Abby for some digestive issues. ... 2013-01-17 00:05:43  \n",
       "3  Abby helped me with some longstanding issues, ... 2015-03-16 03:43:08  \n",
       "4  Recently, I referred a patient of mine with mu... 2013-03-05 18:45:07  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_merged_df = pd.merge(yelp_business, yelp_reviews, on='business_id')\n",
    "yelp_merged_df.rename(columns={'stars_y': 'stars'}, inplace=True)\n",
    "yelp_merged_df.drop(columns=['stars_x'], inplace=True)\n",
    "yelp_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e69708-cabc-4e4f-96cb-a2fad194e182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6990280, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66245a32-bd7d-4f6c-beae-1264f08ce7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3773971, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_df = yelp_merged_df[yelp_merged_df['categories'].str.contains('Restaurant', case=False, na=False)]\n",
    "restaurants_df = restaurants_df.query('is_open == 1')\n",
    "restaurants_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b9849d0-8c85-4d64-aa22-2938b66c1d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>...</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "      <td>BXQcBN0iAi1lAUxibGLFzA</td>\n",
       "      <td>6_SpY41LIHZuIaiDs5FMKA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This is nice little Chinese bakery in the hear...</td>\n",
       "      <td>2014-05-26 01:09:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "      <td>uduvUCvi9w3T2bSGivCfXg</td>\n",
       "      <td>tCXElwhzekJEH6QJe3xs7Q</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>This is the bakery I usually go to in Chinatow...</td>\n",
       "      <td>2013-10-05 15:19:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "      <td>a0vwPOqDXXZuJkbBW2356g</td>\n",
       "      <td>WqfKtI-aGMmvbA9pPUxNQQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A delightful find in Chinatown! Very clean, an...</td>\n",
       "      <td>2013-10-25 01:34:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "      <td>MKNp_CdR2k2202-c8GN5Dw</td>\n",
       "      <td>3-1va0IQfK-9tUMzfHWfTA</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>I ordered a graduation cake for my niece and i...</td>\n",
       "      <td>2018-05-20 17:58:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "      <td>D1GisLDPe84Rrk_R4X2brQ</td>\n",
       "      <td>EouCKoDfzaVG0klEgdDvCQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HK-STYLE MILK TEA:  FOUR STARS\\n\\nNot quite su...</td>\n",
       "      <td>2013-10-25 02:31:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id                name      address          city  \\\n",
       "46  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  935 Race St  Philadelphia   \n",
       "47  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  935 Race St  Philadelphia   \n",
       "48  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  935 Race St  Philadelphia   \n",
       "49  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  935 Race St  Philadelphia   \n",
       "50  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  935 Race St  Philadelphia   \n",
       "\n",
       "   state postal_code   latitude  longitude  review_count  is_open  ...  \\\n",
       "46    PA       19107  39.955505 -75.155564            80        1  ...   \n",
       "47    PA       19107  39.955505 -75.155564            80        1  ...   \n",
       "48    PA       19107  39.955505 -75.155564            80        1  ...   \n",
       "49    PA       19107  39.955505 -75.155564            80        1  ...   \n",
       "50    PA       19107  39.955505 -75.155564            80        1  ...   \n",
       "\n",
       "                                           categories  \\\n",
       "46  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "47  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "48  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "49  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "50  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "\n",
       "                                                hours               review_id  \\\n",
       "46  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  BXQcBN0iAi1lAUxibGLFzA   \n",
       "47  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  uduvUCvi9w3T2bSGivCfXg   \n",
       "48  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  a0vwPOqDXXZuJkbBW2356g   \n",
       "49  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  MKNp_CdR2k2202-c8GN5Dw   \n",
       "50  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  D1GisLDPe84Rrk_R4X2brQ   \n",
       "\n",
       "                   user_id stars  useful  funny  cool  \\\n",
       "46  6_SpY41LIHZuIaiDs5FMKA     4       0      0     1   \n",
       "47  tCXElwhzekJEH6QJe3xs7Q     4       3      1     2   \n",
       "48  WqfKtI-aGMmvbA9pPUxNQQ     5       0      0     0   \n",
       "49  3-1va0IQfK-9tUMzfHWfTA     5       5      0     5   \n",
       "50  EouCKoDfzaVG0klEgdDvCQ     4       2      1     1   \n",
       "\n",
       "                                                 text                date  \n",
       "46  This is nice little Chinese bakery in the hear... 2014-05-26 01:09:53  \n",
       "47  This is the bakery I usually go to in Chinatow... 2013-10-05 15:19:06  \n",
       "48  A delightful find in Chinatown! Very clean, an... 2013-10-25 01:34:57  \n",
       "49  I ordered a graduation cake for my niece and i... 2018-05-20 17:58:57  \n",
       "50  HK-STYLE MILK TEA:  FOUR STARS\\n\\nNot quite su... 2013-10-25 02:31:35  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c4f516-14a9-4147-abd7-32e4e924d2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1277330"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e4953ea-301a-456f-9b68-0636a0cbe55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35004"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_df['business_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf1cb45-ac51-435e-90c3-bca4f2801bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51618, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected a subset with customers and business with at least 100 and 500 reviews\n",
    "# Step 1: Filter customers with at least 100 reviews\n",
    "yelp_customer_review_counts = restaurants_df.groupby('user_id').size().reset_index(name='user_review_count')\n",
    "yelp_customers_with_at_least_100_reviews = yelp_customer_review_counts[yelp_customer_review_counts['user_review_count'] >= 100] \n",
    "# Step 2: Filter products with at least 500 reviews\n",
    "yelp_review_counts = restaurants_df.groupby('business_id').size().reset_index(name='business_review_count')\n",
    "yelp_with_at_least_100_reviews = yelp_review_counts[yelp_review_counts['business_review_count'] >= 500]\n",
    "\n",
    "# Step 3: Filter the original dataset to only include customers and products with at least 100 and 500 reviews\n",
    "yelp_filtered_data = restaurants_df[\n",
    "    (restaurants_df['user_id'].isin(yelp_customers_with_at_least_100_reviews['user_id'])) & # This filter may need correction. A user might have contributed at least 100 reviews overall, but not necessarily to businesses meeting the >= 500 reviews condition.\n",
    "    (restaurants_df['business_id'].isin(yelp_with_at_least_100_reviews['business_id'])) # Is this the expected behavior?\n",
    "]\n",
    "yelp_filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b960fb57-3177-4b15-b014-6c2d64bc4527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_filtered_data['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe902d88-98d0-46e5-a3ea-c13ad2cac496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1227"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_filtered_data['business_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f1a4029-efb0-4724-8262-fd69f1733d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key = \"user_id\"\n",
    "item_key = \"business_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "005929b1-5cf9-4884-ad22-5e33ea9e18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of ratings per customer : 36.66\n",
      "Average number of ratings per product: 42.07\n"
     ]
    }
   ],
   "source": [
    "avg_nratings_per_user = yelp_filtered_data.groupby(user_key).size().mean()\n",
    "avg_nratings_per_movie = yelp_filtered_data.groupby(item_key).size().mean()\n",
    "print(f\"Average number of ratings per customer : {avg_nratings_per_user:.2f}\")\n",
    "print(f\"Average number of ratings per product: {avg_nratings_per_movie:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1435eaa-e822-4a3b-9f85-80a15001391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51618 entries, 4493 to 6989787\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   business_id   51618 non-null  object        \n",
      " 1   name          51618 non-null  object        \n",
      " 2   address       51618 non-null  object        \n",
      " 3   city          51618 non-null  object        \n",
      " 4   state         51618 non-null  object        \n",
      " 5   postal_code   51618 non-null  object        \n",
      " 6   latitude      51618 non-null  float64       \n",
      " 7   longitude     51618 non-null  float64       \n",
      " 8   review_count  51618 non-null  int64         \n",
      " 9   is_open       51618 non-null  int64         \n",
      " 10  attributes    51618 non-null  object        \n",
      " 11  categories    51618 non-null  object        \n",
      " 12  hours         51536 non-null  object        \n",
      " 13  review_id     51618 non-null  object        \n",
      " 14  user_id       51618 non-null  object        \n",
      " 15  stars         51618 non-null  int64         \n",
      " 16  useful        51618 non-null  int64         \n",
      " 17  funny         51618 non-null  int64         \n",
      " 18  cool          51618 non-null  int64         \n",
      " 19  text          51618 non-null  object        \n",
      " 20  date          51618 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(6), object(12)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "yelp_filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5165eb6e-55aa-4841-ad06-ae119c1ef2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id      0\n",
       "name             0\n",
       "address          0\n",
       "city             0\n",
       "state            0\n",
       "postal_code      0\n",
       "latitude         0\n",
       "longitude        0\n",
       "review_count     0\n",
       "is_open          0\n",
       "attributes       0\n",
       "categories       0\n",
       "hours           82\n",
       "review_id        0\n",
       "user_id          0\n",
       "stars            0\n",
       "useful           0\n",
       "funny            0\n",
       "cool             0\n",
       "text             0\n",
       "date             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_filtered_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d837ed7f-b14c-4dff-aabc-f829708543bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_filtered_data = yelp_filtered_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d26dbb4-c8da-473f-9f96-7ec854ee7034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id     0\n",
       "name            0\n",
       "address         0\n",
       "city            0\n",
       "state           0\n",
       "postal_code     0\n",
       "latitude        0\n",
       "longitude       0\n",
       "review_count    0\n",
       "is_open         0\n",
       "attributes      0\n",
       "categories      0\n",
       "hours           0\n",
       "review_id       0\n",
       "user_id         0\n",
       "stars           0\n",
       "useful          0\n",
       "funny           0\n",
       "cool            0\n",
       "text            0\n",
       "date            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_filtered_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc2c54b5-f3ae-491c-9324-4ef295a95839",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_filtered_data.to_csv('data/yelp_reviews_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c6424-b760-426a-a63c-6b4422680d85",
   "metadata": {},
   "source": [
    "### Continue on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "81ee4cd0-da0a-47d4-95c0-a084048f051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>...</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>Mike's Ice Cream</td>\n",
       "      <td>129 2nd Ave N</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37201</td>\n",
       "      <td>36.162649</td>\n",
       "      <td>-86.775973</td>\n",
       "      <td>593</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt, Coffee &amp; Tea, Resta...</td>\n",
       "      <td>{'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...</td>\n",
       "      <td>ljQTQY59Rjat2CQd02nYbQ</td>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I ducked in here after walking the strip on a ...</td>\n",
       "      <td>2012-09-17 13:59:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>Mike's Ice Cream</td>\n",
       "      <td>129 2nd Ave N</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37201</td>\n",
       "      <td>36.162649</td>\n",
       "      <td>-86.775973</td>\n",
       "      <td>593</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt, Coffee &amp; Tea, Resta...</td>\n",
       "      <td>{'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...</td>\n",
       "      <td>smLabVSu-w9VFHA7gNLW6A</td>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>For a long time, I wondered how long downtown ...</td>\n",
       "      <td>2009-08-13 02:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>Mike's Ice Cream</td>\n",
       "      <td>129 2nd Ave N</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37201</td>\n",
       "      <td>36.162649</td>\n",
       "      <td>-86.775973</td>\n",
       "      <td>593</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt, Coffee &amp; Tea, Resta...</td>\n",
       "      <td>{'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...</td>\n",
       "      <td>rPZcnwOlfk6IOGXRyRrYCA</td>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ice cream in the dead of winter? Yes, it was a...</td>\n",
       "      <td>2010-01-21 04:08:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>Mike's Ice Cream</td>\n",
       "      <td>129 2nd Ave N</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37201</td>\n",
       "      <td>36.162649</td>\n",
       "      <td>-86.775973</td>\n",
       "      <td>593</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt, Coffee &amp; Tea, Resta...</td>\n",
       "      <td>{'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...</td>\n",
       "      <td>5ViCByByt6xSFyYvQAwdcw</td>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quite possibly the best ice cream I have ever ...</td>\n",
       "      <td>2012-06-17 18:06:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>Mike's Ice Cream</td>\n",
       "      <td>129 2nd Ave N</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37201</td>\n",
       "      <td>36.162649</td>\n",
       "      <td>-86.775973</td>\n",
       "      <td>593</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt, Coffee &amp; Tea, Resta...</td>\n",
       "      <td>{'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...</td>\n",
       "      <td>Yx5D1TZWmbjuVerYi6T9eA</td>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a great place if you're downtown and w...</td>\n",
       "      <td>2009-01-29 14:18:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id              name        address       city state  \\\n",
       "0  oaboaRBUgGjbo2kfUIKDLQ  Mike's Ice Cream  129 2nd Ave N  Nashville    TN   \n",
       "1  oaboaRBUgGjbo2kfUIKDLQ  Mike's Ice Cream  129 2nd Ave N  Nashville    TN   \n",
       "2  oaboaRBUgGjbo2kfUIKDLQ  Mike's Ice Cream  129 2nd Ave N  Nashville    TN   \n",
       "3  oaboaRBUgGjbo2kfUIKDLQ  Mike's Ice Cream  129 2nd Ave N  Nashville    TN   \n",
       "4  oaboaRBUgGjbo2kfUIKDLQ  Mike's Ice Cream  129 2nd Ave N  Nashville    TN   \n",
       "\n",
       "   postal_code   latitude  longitude  review_count  is_open  ...  \\\n",
       "0        37201  36.162649 -86.775973           593        1  ...   \n",
       "1        37201  36.162649 -86.775973           593        1  ...   \n",
       "2        37201  36.162649 -86.775973           593        1  ...   \n",
       "3        37201  36.162649 -86.775973           593        1  ...   \n",
       "4        37201  36.162649 -86.775973           593        1  ...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Ice Cream & Frozen Yogurt, Coffee & Tea, Resta...   \n",
       "1  Ice Cream & Frozen Yogurt, Coffee & Tea, Resta...   \n",
       "2  Ice Cream & Frozen Yogurt, Coffee & Tea, Resta...   \n",
       "3  Ice Cream & Frozen Yogurt, Coffee & Tea, Resta...   \n",
       "4  Ice Cream & Frozen Yogurt, Coffee & Tea, Resta...   \n",
       "\n",
       "                                               hours               review_id  \\\n",
       "0  {'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...  ljQTQY59Rjat2CQd02nYbQ   \n",
       "1  {'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...  smLabVSu-w9VFHA7gNLW6A   \n",
       "2  {'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...  rPZcnwOlfk6IOGXRyRrYCA   \n",
       "3  {'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...  5ViCByByt6xSFyYvQAwdcw   \n",
       "4  {'Monday': '8:0-23:0', 'Tuesday': '8:0-23:0', ...  Yx5D1TZWmbjuVerYi6T9eA   \n",
       "\n",
       "                  user_id stars  useful  funny  cool  \\\n",
       "0  2iS1vg5TYpV_iEiNC8osTg     2       2      1     1   \n",
       "1  ZcNLb0XgmVOPcYvElhz3WA     4       0      0     0   \n",
       "2  TylOr9YYTV3znqIvH7kdmQ     4       1      0     0   \n",
       "3  zfD3xhVNkGJs-AOOSslqtQ     5       0      0     0   \n",
       "4  KGmDAZI48MtoS_SnSkM0ag     3       0      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  I ducked in here after walking the strip on a ...  2012-09-17 13:59:20  \n",
       "1  For a long time, I wondered how long downtown ...  2009-08-13 02:33:39  \n",
       "2  Ice cream in the dead of winter? Yes, it was a...  2010-01-21 04:08:53  \n",
       "3  Quite possibly the best ice cream I have ever ...  2012-06-17 18:06:28  \n",
       "4  This is a great place if you're downtown and w...  2009-01-29 14:18:14  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df = pd.read_csv('data/yelp_reviews_subset.csv')\n",
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "73080755-3df5-4bc2-a0d5-111c8a3577bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     user_id  review_count\n",
      "0     -3s52C4zL_DHRK0ULG6qtg            34\n",
      "1     -7XrSrJfHndHc_taEXurTw            27\n",
      "2     -7qUbOVWJp2NT3f_TNuIBA            29\n",
      "3     -B-QEUESGWHPE_889WJaeg            63\n",
      "4     -CzwjrantVGMmZB8Qj_7-Q            35\n",
      "...                      ...           ...\n",
      "1403  zkQi7B9b-yFbF8k2XSnDHQ            39\n",
      "1404  zsXoPyTcU8ThZGbtAB-Vug            42\n",
      "1405  zu-e06_BM_TdkAZEKMrIww            56\n",
      "1406  zv7tpu7xeaNyAeFG03d2CA            15\n",
      "1407  zyvxtbh5eJ86bVgk52Yflg            33\n",
      "\n",
      "[1379 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by user_id and count reviews\n",
    "user_review_counts = yelp_df.groupby('user_id').size().reset_index(name='review_count')\n",
    "\n",
    "# Find users with fewer than 100 reviews\n",
    "users_below_100 = user_review_counts[user_review_counts['review_count'] < 100]\n",
    "print(users_below_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3b100bff-b849-425e-80a2-8c0eaabd29c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51536, 21)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1a153867-f417-485e-ae1e-00084cf64d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 5, 3, 1])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df['stars'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0cc902ad-9831-4145-a01a-f6f79eaa4388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  stars\n",
       "0  2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ      2\n",
       "1  ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ      4\n",
       "2  TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ      4\n",
       "3  zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ      5\n",
       "4  KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ      3"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "colab_data = yelp_df[['user_id', 'business_id', 'stars']].reset_index(drop=True)\n",
    "colab_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b71dd1d-440c-43a0-93c1-94a7c23d0dd9",
   "metadata": {},
   "source": [
    "#### Normalizing the stars column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91a6b0-1e28-41ef-bc4a-d71ce0a10916",
   "metadata": {},
   "source": [
    "Normalizing to adjust the ratings so that they are relative to each user or item, rather than being treated as absolute values. \n",
    "\n",
    "This process helps to account for different rating behaviors among users or differing popularity across items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39be3a3-84e5-448f-8190-ce74c781e1ee",
   "metadata": {},
   "source": [
    "**User Bias:** Some users might generally rate items higher or lower than others. For instance, one user might rate most restaurants as 5 stars while another user might be more conservative and give an average of 3 stars. Normalization helps reduce this bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633cb2dc-e169-4f6c-9fc5-036764561855",
   "metadata": {},
   "source": [
    "**Improved Similarity Calculations:** When calculating similarities between users or items, normalization can improve the accuracy of those measures by removing biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "153aa5af-8cad-46f9-8c99-b3fabf785f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>normalized_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  stars  normalized_stars\n",
       "0  2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ      2         -1.771429\n",
       "1  ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ      4          0.769231\n",
       "2  TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ      4          0.509434\n",
       "3  zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ      5          1.333333\n",
       "4  KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ      3         -0.800000"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by user_id and calculate the mean rating for each user\n",
    "user_mean = colab_data.groupby('user_id')['stars'].transform('mean')\n",
    "\n",
    "# Subtract the mean rating for each user from their individual ratings\n",
    "colab_data['normalized_stars'] = colab_data['stars'] - user_mean\n",
    "colab_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "87d7a309-29cf-4bbb-8c9f-d04aa1041e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-nan ratings percentage: 2.99\n"
     ]
    }
   ],
   "source": [
    "non_nan_ratings_percentage = (len(colab_data) / (N * M) * 100) \n",
    "print(f\"Non-nan ratings percentage: {np.round(non_nan_ratings_percentage,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "de07ef5e-4769-4b75-ae0e-e77c1f5245cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of ratings per customer : 36.60\n",
      "Average number of ratings per product: 42.10\n"
     ]
    }
   ],
   "source": [
    "avg_nratings_per_user = colab_data.groupby(user_key).size().mean()\n",
    "avg_nratings_per_movie = colab_data.groupby(item_key).size().mean()\n",
    "print(f\"Average number of ratings per customer : {avg_nratings_per_user:.2f}\")\n",
    "print(f\"Average number of ratings per product: {avg_nratings_per_movie:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a992d6eb-93a6-4bc2-ba6b-312a751d2e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'business_id', 'stars', 'normalized_stars'], dtype='object')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colab_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8757f-0619-4ca3-93a6-9ab8356fda55",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78174fef-6226-471b-8538-8f7746b612fb",
   "metadata": {},
   "source": [
    "#### 1- Business Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fcd26-a7cc-4764-a486-410911ab2d8a",
   "metadata": {},
   "source": [
    "Business popularity can be defined as the number of reviews it has received. I will create a business_popularity feature that we can merge into the dataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0e5ff9f4-b520-40a7-a6e9-416bc60a8b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>normalized_stars</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.771429</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51531</th>\n",
       "      <td>StZTVDuFzahNvjl5qu6l7Q</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51532</th>\n",
       "      <td>E5Qm5W2BsMFCTirHq4DEIQ</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51533</th>\n",
       "      <td>G9P3h7ZGdbdc_Zt6IKC2vQ</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.163934</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51534</th>\n",
       "      <td>ERh66eWeg5pQkA-vWpmx0Q</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51535</th>\n",
       "      <td>CHuttPq3PpoKgdYnxAYKHQ</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51536 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id             business_id  stars  \\\n",
       "0      2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ      2   \n",
       "1      ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ      4   \n",
       "2      TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ      4   \n",
       "3      zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ      5   \n",
       "4      KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ      3   \n",
       "...                       ...                     ...    ...   \n",
       "51531  StZTVDuFzahNvjl5qu6l7Q  w_4xUt-1AyY2ZwKtnjW0Xg      4   \n",
       "51532  E5Qm5W2BsMFCTirHq4DEIQ  w_4xUt-1AyY2ZwKtnjW0Xg      1   \n",
       "51533  G9P3h7ZGdbdc_Zt6IKC2vQ  w_4xUt-1AyY2ZwKtnjW0Xg      2   \n",
       "51534  ERh66eWeg5pQkA-vWpmx0Q  w_4xUt-1AyY2ZwKtnjW0Xg      5   \n",
       "51535  CHuttPq3PpoKgdYnxAYKHQ  w_4xUt-1AyY2ZwKtnjW0Xg      5   \n",
       "\n",
       "       normalized_stars  popularity  \n",
       "0             -1.771429          19  \n",
       "1              0.769231          19  \n",
       "2              0.509434          19  \n",
       "3              1.333333          19  \n",
       "4             -0.800000          19  \n",
       "...                 ...         ...  \n",
       "51531          0.238095           9  \n",
       "51532         -1.666667           9  \n",
       "51533         -2.163934           9  \n",
       "51534          0.966667           9  \n",
       "51535          0.142857           9  \n",
       "\n",
       "[51536 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate business popularity: number of reviews for each business\n",
    "business_popularity_data = colab_data.groupby('business_id')['user_id'].count().reset_index()\n",
    "business_popularity_data.columns = ['business_id', 'popularity']\n",
    "\n",
    "# Merge this popularity feature back to the main data frame\n",
    "colab_data = colab_data.merge(business_popularity_data, on='business_id', how='left')\n",
    "\n",
    "colab_data[['user_id', 'business_id', 'stars', 'normalized_stars', 'popularity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b15ee-43d5-48f7-aece-ddbd6a79b091",
   "metadata": {},
   "source": [
    "#### 2- User Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad34f0e-0821-467a-995b-7e1c70c17e25",
   "metadata": {},
   "source": [
    "User activity can be defined as the number of businesses reviewed by a user. I can calculate this and add it as a new feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d89be787-2f65-4ceb-91d3-ec4e01f28d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>normalized_stars</th>\n",
       "      <th>popularity</th>\n",
       "      <th>activity_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.771429</td>\n",
       "      <td>19</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51531</th>\n",
       "      <td>StZTVDuFzahNvjl5qu6l7Q</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51532</th>\n",
       "      <td>E5Qm5W2BsMFCTirHq4DEIQ</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51533</th>\n",
       "      <td>G9P3h7ZGdbdc_Zt6IKC2vQ</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.163934</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51534</th>\n",
       "      <td>ERh66eWeg5pQkA-vWpmx0Q</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51535</th>\n",
       "      <td>CHuttPq3PpoKgdYnxAYKHQ</td>\n",
       "      <td>w_4xUt-1AyY2ZwKtnjW0Xg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51536 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id             business_id  stars  \\\n",
       "0      2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ      2   \n",
       "1      ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ      4   \n",
       "2      TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ      4   \n",
       "3      zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ      5   \n",
       "4      KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ      3   \n",
       "...                       ...                     ...    ...   \n",
       "51531  StZTVDuFzahNvjl5qu6l7Q  w_4xUt-1AyY2ZwKtnjW0Xg      4   \n",
       "51532  E5Qm5W2BsMFCTirHq4DEIQ  w_4xUt-1AyY2ZwKtnjW0Xg      1   \n",
       "51533  G9P3h7ZGdbdc_Zt6IKC2vQ  w_4xUt-1AyY2ZwKtnjW0Xg      2   \n",
       "51534  ERh66eWeg5pQkA-vWpmx0Q  w_4xUt-1AyY2ZwKtnjW0Xg      5   \n",
       "51535  CHuttPq3PpoKgdYnxAYKHQ  w_4xUt-1AyY2ZwKtnjW0Xg      5   \n",
       "\n",
       "       normalized_stars  popularity  activity_level  \n",
       "0             -1.771429          19              70  \n",
       "1              0.769231          19              13  \n",
       "2              0.509434          19              53  \n",
       "3              1.333333          19              30  \n",
       "4             -0.800000          19              15  \n",
       "...                 ...         ...             ...  \n",
       "51531          0.238095           9              21  \n",
       "51532         -1.666667           9               9  \n",
       "51533         -2.163934           9              61  \n",
       "51534          0.966667           9              30  \n",
       "51535          0.142857           9               7  \n",
       "\n",
       "[51536 rows x 6 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate user activity: number of businesses reviewed by each user\n",
    "user_activity_data = colab_data.groupby('user_id')['business_id'].count().reset_index()\n",
    "user_activity_data.columns = ['user_id', 'activity_level']\n",
    "\n",
    "# Merge the user activity feature into the data frame\n",
    "colab_data = colab_data.merge(user_activity_data, on='user_id', how='left')\n",
    "\n",
    "colab_data[['user_id', 'business_id', 'stars', 'normalized_stars', 'popularity', 'activity_level']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "29e7cefd-10ee-4d80-9801-916900c9a7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  stars\n",
       "0  2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ      2\n",
       "1  ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ      4\n",
       "2  TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ      4\n",
       "3  zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ      5\n",
       "4  KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ      3"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a copy \n",
    "colab_data_1 = colab_data.copy()\n",
    "colab_data_1 = colab_data_1.drop(['normalized_stars', 'popularity', 'activity_level'], axis=1)\n",
    "colab_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cec6bb0a-1430-4834-897f-3dd11869fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = colab_data_1.copy()\n",
    "y = colab_data_1['user_id']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "82574082-de35-440b-a8c8-201d322475ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(colab_data_1[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(colab_data_1[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(colab_data_1[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(colab_data_1[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6a5903e-208d-43ae-9cd8-e3633b59e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create utility matrix\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"stars\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "60800f03-aca2-445e-a0aa-bedf68964ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan,  5.],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], shape=(1408, 1224))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "924c4571-9a46-489e-9ab7-dbae9867b94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-nan elements in train_mat: 37218\n",
      "Number of non-nan elements in valid_mat: 10030\n"
     ]
    }
   ],
   "source": [
    "# What's the number of non-nan elements in train_mat (nnn_train_mat)?\n",
    "nnn_train_mat = np.sum(~np.isnan(train_mat)) \n",
    "\n",
    "# What's the number of non-nan elements in valid_mat (nnn_valid_mat)?\n",
    "nnn_valid_mat = np.sum(~np.isnan(valid_mat)) \n",
    "print(f\"Number of non-nan elements in train_mat: {nnn_train_mat}\")\n",
    "print(f\"Number of non-nan elements in valid_mat: {nnn_valid_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0a09e1f7-6b66-43b3-8d7d-864caf4924c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "    # Calculate the range of Y1 (ignoring NaN values)\n",
    "    range_Y2 = np.nanmax(Y2) - np.nanmin(Y2)\n",
    "\n",
    "    # Calculate relative RMSE\n",
    "    relative_rmse = rmse / range_Y2 if range_Y2 != 0 else np.nan\n",
    "\n",
    "    return relative_rmse\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "21b5fef5-56b8-4f80-a1b1-297acbc90465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.24\n",
      "Global average valid RMSE: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8b1bdd3e-b2fe-4297-ac13-c8b12d88855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train RMSE: 0.22\n",
      "Per-user average valid RMSE: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat, valid_mat, model_name=\"Per-user average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c67ec774-3810-4b5f-8e77-78f7e51d7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-product average train RMSE: 0.22\n",
      "Per-product average valid RMSE: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-restaurant average baseline\n",
    "avg_m = np.nanmean(train_mat, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat, valid_mat, model_name=\"Per-product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0c1ea2b2-4698-45a6-96d4-6826e130ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and product average train RMSE: 0.21\n",
      "Per-user and product average valid RMSE: 0.22\n"
     ]
    }
   ],
   "source": [
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat, valid_mat, model_name=\"Per-user and product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b21a038-5e35-4c9c-8a0d-cbf06c7c3dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat)\n",
    "    evaluate(pred_knn, train_mat, valid_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "60f686e4-d5b2-4077-9b86-9f4aa79710b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.20\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.22\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.17\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.22\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.15\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.22\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.11\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.23\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.04\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.23\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.00\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Collaborative filtering with TruncatedSVD()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat, valid_mat, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "69548666-bfa2-4f08-b141-e3880bf3710e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using surprise package\n",
    "# from surprise import Reader\n",
    "\n",
    "\n",
    "# reader = Reader()\n",
    "# data = Dataset.load_from_df(coll_data, reader)  \n",
    "\n",
    "# k = 10\n",
    "# algo = SVD(n_factors=k, random_state=42)\n",
    "# pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\"], cv=5, verbose=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d53c8-8e8c-4782-a88a-8380d073f2c1",
   "metadata": {},
   "source": [
    "Lets now use the other features for creating the utility matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38392b0a-a759-48ca-8323-b1c086a4d420",
   "metadata": {},
   "source": [
    "#### normalized_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2796e25d-886a-48cb-b935-7c8d0e35706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>normalized_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>-1.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  normalized_stars\n",
       "0  2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ         -1.771429\n",
       "1  ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ          0.769231\n",
       "2  TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ          0.509434\n",
       "3  zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ          1.333333\n",
       "4  KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ         -0.800000"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a copy \n",
    "colab_data_2 = colab_data.copy()\n",
    "colab_data_2 = colab_data_2.drop(['stars', 'popularity', 'activity_level'], axis=1)\n",
    "colab_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "05474197-2874-4a6a-ac17-22bd84662317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = colab_data_2.copy()\n",
    "y = colab_data_2['user_id']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fb9e1bee-98e5-412b-96aa-89ae9c0bf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(colab_data_2[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(colab_data_2[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(colab_data_2[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(colab_data_2[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2768cc99-4651-47ce-ab65-3c71340a6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create utility matrix\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"normalized_stars\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "946fdfe3-93e3-4469-b63f-667c8fd61e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "        0.55172414],\n",
       "       ...,\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan]], shape=(1408, 1224))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0b702163-5c78-4607-822e-82ce1047bcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.13\n",
      "Global average valid RMSE: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fcd25443-f97b-4e61-b5d1-dc5a3db91e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train RMSE: 0.13\n",
      "Per-user average valid RMSE: 0.16\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat, valid_mat, model_name=\"Per-user average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2827b699-b5a6-4f11-86cb-6b4e39bd94c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-product average train RMSE: 0.12\n",
      "Per-product average valid RMSE: 0.14\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-restaurant average baseline\n",
    "avg_m = np.nanmean(train_mat, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat, valid_mat, model_name=\"Per-product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "617db03c-881f-4fdb-a72e-9dee7e1a4dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and product average train RMSE: 0.13\n",
      "Per-user and product average valid RMSE: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat, valid_mat, model_name=\"Per-user and product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "00aca692-1a01-4ffa-a5e0-022a52e7c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.16\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.15\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.15\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.15\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.15\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat)\n",
    "    evaluate(pred_knn, train_mat, valid_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead7107-0ecc-4572-9c65-4936cccc19bc",
   "metadata": {},
   "source": [
    "So far so good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962f809-d3ff-4bd9-8a0f-06a1c1b82645",
   "metadata": {},
   "source": [
    "Now, lets incorporate the `popularity` and `activity_level` as weights for the original matrix that is created from `normalized_stars` and not `stars`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a585188-6352-47a6-85a0-53b0e1320698",
   "metadata": {},
   "source": [
    "##### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d9b610cf-c40e-46bc-9fd7-6dcbcd302dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  popularity\n",
       "0  2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ          19\n",
       "1  ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ          19\n",
       "2  TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ          19\n",
       "3  zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ          19\n",
       "4  KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ          19"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a copy \n",
    "colab_data_pop = colab_data.copy()\n",
    "colab_data_pop = colab_data_pop.drop(['stars', 'normalized_stars','activity_level'], axis=1)\n",
    "colab_data_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f2e2acb1-65a3-4350-ad5a-2b8916e62305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_pop = colab_data_pop.copy()\n",
    "y_pop = colab_data_pop['user_id']\n",
    "X_train_pop, X_valid_pop, y_train_pop, y_valid_pop = train_test_split(X_pop, y_pop, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9d8e985e-7ec1-4cd0-bc80-686765c46b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper_pop = dict(zip(np.unique(colab_data_pop[user_key]), list(range(N))))\n",
    "item_mapper_pop = dict(zip(np.unique(colab_data_pop[item_key]), list(range(M))))\n",
    "user_inverse_mapper_pop = dict(zip(list(range(N)), np.unique(colab_data_pop[user_key])))\n",
    "item_inverse_mapper_pop = dict(zip(list(range(M)), np.unique(colab_data_pop[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "86e0fee9-df8e-4be6-996f-cff0b22e099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create utility matrix for Popularity\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"popularity\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "train_mat_pop = create_Y_from_ratings(X_train_pop, N, M)\n",
    "valid_mat_pop = create_Y_from_ratings(X_valid_pop, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a38fe5f3-57d2-4222-b938-a12cf4e13ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, 34.],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], shape=(1408, 1224))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ec6f96b6-4df7-4ba2-9c15-64fed7809cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize modifier matrice popularity\n",
    "train_mat_pop_normalized = train_mat_pop / np.nanmax(train_mat_pop)\n",
    "valid_mat_pop_normalized = valid_mat_pop / np.nanmax(valid_mat_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a5a35-9f8f-4292-b8d6-1f2ce82094bd",
   "metadata": {},
   "source": [
    "##### Activity_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ecabde6c-6417-4051-a4f0-004947eb30e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>activity_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2iS1vg5TYpV_iEiNC8osTg</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZcNLb0XgmVOPcYvElhz3WA</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TylOr9YYTV3znqIvH7kdmQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zfD3xhVNkGJs-AOOSslqtQ</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KGmDAZI48MtoS_SnSkM0ag</td>\n",
       "      <td>oaboaRBUgGjbo2kfUIKDLQ</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  activity_level\n",
       "0  2iS1vg5TYpV_iEiNC8osTg  oaboaRBUgGjbo2kfUIKDLQ              70\n",
       "1  ZcNLb0XgmVOPcYvElhz3WA  oaboaRBUgGjbo2kfUIKDLQ              13\n",
       "2  TylOr9YYTV3znqIvH7kdmQ  oaboaRBUgGjbo2kfUIKDLQ              53\n",
       "3  zfD3xhVNkGJs-AOOSslqtQ  oaboaRBUgGjbo2kfUIKDLQ              30\n",
       "4  KGmDAZI48MtoS_SnSkM0ag  oaboaRBUgGjbo2kfUIKDLQ              15"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a copy \n",
    "colab_data_al = colab_data.copy()\n",
    "colab_data_al = colab_data_al.drop(['stars', 'normalized_stars','popularity'], axis=1)\n",
    "colab_data_al.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8319b10d-4cbc-4622-aa1c-98e95d4bdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_al = colab_data_al.copy()\n",
    "y_al = colab_data_al['user_id']\n",
    "X_train_al, X_valid_al, y_train_al, y_valid_al = train_test_split(X_al, y_al, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "abf2f6d4-5a17-4aba-b713-ad70be27bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper_al = dict(zip(np.unique(colab_data_al[user_key]), list(range(N))))\n",
    "item_mapper_al = dict(zip(np.unique(colab_data_al[item_key]), list(range(M))))\n",
    "user_inverse_mapper_al = dict(zip(list(range(N)), np.unique(colab_data_al[user_key])))\n",
    "item_inverse_mapper_al = dict(zip(list(range(M)), np.unique(colab_data_al[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ee7139ab-fada-4e0e-99b7-6a90f25853bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create utility matrix for Activity_level\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"activity_level\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "train_mat_al = create_Y_from_ratings(X_train_al, N, M)\n",
    "valid_mat_al = create_Y_from_ratings(X_valid_al, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "81f76a3e-af5f-4991-9921-024226ab531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, 29.],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], shape=(1408, 1224))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "98ae7569-9661-489e-b0d2-b54f5e86c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize modifier matrice acticvity_level\n",
    "train_mat_al_normalized = train_mat_al / np.nanmax(train_mat_al)\n",
    "valid_mat_al_normalized = valid_mat_al / np.nanmax(valid_mat_al)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971f284-c71a-4bfb-baf8-d9bbcdc619ac",
   "metadata": {},
   "source": [
    "##### Applying the weight modifiers to the main matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d35c457f-6f07-4cfe-bb14-800666eb6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply modifiers to the main matrix\n",
    "train_mat_final = train_mat * train_mat_pop_normalized\n",
    "valid_mat_final = valid_mat * valid_mat_pop_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bdb0e4eb-a1a2-43c9-bc4f-23002abbce37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "        0.08411938],\n",
       "       ...,\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan]], shape=(1408, 1224))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f97a87dd-4d53-4dbd-a426-e56e5ea8ca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.06\n",
      "Global average valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat_final)\n",
    "pred_g = np.zeros(train_mat_final.shape) + avg\n",
    "evaluate(pred_g, train_mat_final, valid_mat_final, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "05db79b9-78ae-451f-95e9-3d15dd5db4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train RMSE: 0.06\n",
      "Per-user average valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat_final, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat_final, valid_mat_final, model_name=\"Per-user average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "69f54860-5ae4-4ddd-b621-d81463168901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-product average train RMSE: 0.05\n",
      "Per-product average valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-restaurant average baseline\n",
    "avg_m = np.nanmean(train_mat_final, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat_final, valid_mat_final, model_name=\"Per-product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ad6eaa64-00a1-402a-af63-8f070f3e2d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and product average train RMSE: 0.05\n",
      "Per-user and product average valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat_final, valid_mat_final, model_name=\"Per-user and product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cec15b9c-8bc0-4155-9513-77d068b2eea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat_final)\n",
    "    evaluate(pred_knn, train_mat_final, valid_mat_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "691336b1-8f4a-4162-b773-82cd9dbd6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.05\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.03\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.03\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.02\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.01\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.00\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Collaborative filtering with TruncatedSVD()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_final_svd = train_mat_final - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_final_svd = np.nan_to_num(train_mat_final_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_final_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat_final, valid_mat_final, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956da967-da68-4ff5-93e4-9e9cdf32fd17",
   "metadata": {},
   "source": [
    "##### Applying the weight modifiers to the main matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "82f833a6-2d95-42ed-af22-55190c645f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply modifiers to the main matrix\n",
    "train_mat_final = train_mat * train_mat_al_normalized\n",
    "valid_mat_final = valid_mat * valid_mat_al_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "68ea9350-aeef-4689-9976-d41c9044ab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408, 1224)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e5a91c20-b962-40d9-8881-382f6ea5d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.06\n",
      "Global average valid RMSE: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat_final)\n",
    "pred_g = np.zeros(train_mat_final.shape) + avg\n",
    "evaluate(pred_g, train_mat_final, valid_mat_final, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c5a13590-1f18-44c3-abb9-470e08221def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train RMSE: 0.06\n",
      "Per-user average valid RMSE: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat_final, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat_final, valid_mat_final, model_name=\"Per-user average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c9d70da8-f3c7-4bf6-b9a4-1c75f2195c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and product average train RMSE: 0.06\n",
      "Per-user and product average valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat_final, valid_mat_final, model_name=\"Per-user and product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ba28c53c-7f8a-45e3-89e8-a1af917b2aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.07\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.07\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.07\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.07\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.07\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat_final)\n",
    "    evaluate(pred_knn, train_mat_final, valid_mat_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5128d931-743a-4bb7-9dba-c7c8911a25c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.05\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.07\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.04\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.07\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.03\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.07\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.02\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.07\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.01\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.07\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.00\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Collaborative filtering with TruncatedSVD()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_final_svd = train_mat_final - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_final_svd = np.nan_to_num(train_mat_final_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_final_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat_final, valid_mat_final, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fc425-0155-456a-bc9c-a46073caec1b",
   "metadata": {},
   "source": [
    "This seems to give pretty much the same results as the popularity multiplier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc85fe-63aa-4fd8-bedc-cc84de68bfa0",
   "metadata": {},
   "source": [
    "**So we can conclude the these feature engineering does improve the accuracy of the baselines. But to confirm this, it is best to first split the data to train/test and then do the feature engineering for each split separately.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12977114-50c0-47cf-be40-29211003824f",
   "metadata": {},
   "source": [
    "### The same approach but with splitting the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d2d19021-1c22-49a1-bae9-093af6d08041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "colab_data = yelp_df[['user_id', 'business_id', 'stars']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train = colab_data.copy()\n",
    "# y = colab_data['user_id'] # What is the idea behind X & y splits while only the X is used.\n",
    "colab_train, colab_valid = train_test_split(colab_data, test_size=0.2, random_state=123)\n",
    "\n",
    "# Group by user_id and calculate the mean rating for each user\n",
    "user_mean = colab_train.groupby('user_id')['stars'].transform('mean')\n",
    "\n",
    "# Normalizing the stars, train set\n",
    "# Subtract the mean rating for each user from their individual ratings\n",
    "colab_train['normalized_stars'] = colab_train['stars'] - user_mean\n",
    "\n",
    "# Group by user_id and calculate the mean rating for each user\n",
    "user_mean = colab_valid.groupby('user_id')['stars'].transform('mean')\n",
    "\n",
    "# Normalizing the stars, valid set\n",
    "# Subtract the mean rating for each user from their individual ratings\n",
    "colab_valid['normalized_stars'] = colab_valid['stars'] - user_mean\n",
    "\n",
    "# Popularity column\n",
    "# Calculate business popularity: number of reviews for each business\n",
    "business_popularity_train_data = colab_train.groupby('business_id')['user_id'].count().reset_index()\n",
    "business_popularity_train_data.columns = ['business_id', 'popularity']\n",
    "\n",
    "# Merge this popularity feature back to the main data frame\n",
    "colab_train = colab_train.merge(business_popularity_train_data, on='business_id', how='left')\n",
    "\n",
    "colab_train[['user_id', 'business_id', 'stars', 'normalized_stars', 'popularity']]\n",
    "\n",
    "# Calculate business popularity: number of reviews for each business\n",
    "business_popularity_valid_data = colab_valid.groupby('business_id')['user_id'].count().reset_index()\n",
    "business_popularity_valid_data.columns = ['business_id', 'popularity']\n",
    "\n",
    "# Merge this popularity feature back to the main data frame\n",
    "colab_valid = colab_valid.merge(business_popularity_valid_data, on='business_id', how='left')\n",
    "\n",
    "colab_valid[['user_id', 'business_id', 'stars', 'normalized_stars', 'popularity']]\n",
    "\n",
    "# User activity_level column, train set\n",
    "# Calculate user activity: number of businesses reviewed by each user\n",
    "user_activity_train_data = colab_train.groupby('user_id')['business_id'].count().reset_index()\n",
    "user_activity_train_data.columns = ['user_id', 'activity_level']\n",
    "\n",
    "# Merge the user activity feature into the data frame\n",
    "colab_train = colab_train.merge(user_activity_train_data, on='user_id', how='left')\n",
    "\n",
    "colab_train[['user_id', 'business_id', 'stars', 'normalized_stars', 'popularity', 'activity_level']]\n",
    "\n",
    "# User activity_level column, valid set\n",
    "# Calculate user activity: number of businesses reviewed by each user\n",
    "user_activity_valid_data = colab_valid.groupby('user_id')['business_id'].count().reset_index()\n",
    "user_activity_valid_data.columns = ['user_id', 'activity_level']\n",
    "\n",
    "# Merge the user activity feature into the data frame\n",
    "colab_valid = colab_valid.merge(user_activity_valid_data, on='user_id', how='left')\n",
    "\n",
    "colab_valid[['user_id', 'business_id', 'stars', 'normalized_stars', 'popularity', 'activity_level']]\n",
    "\n",
    "# Number of customers and products\n",
    "user_key = \"user_id\"\n",
    "item_key = \"business_id\"\n",
    "N = len(np.unique(colab_data[user_key])) \n",
    "M = len(np.unique(colab_data[item_key]))\n",
    "# print(f\"Number of customers (N)  : {N}\")\n",
    "# print(f\"Number of products (M) : {M}\")\n",
    "\n",
    "# Code for utility matrix\n",
    "user_mapper = dict(zip(np.unique(colab_data[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(colab_data[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(colab_data[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(colab_data[item_key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c71925-67b4-4d84-a688-fd5cf8b6625e",
   "metadata": {},
   "source": [
    "## stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c6be9c0e-4e13-41bc-ae42-244f434dc3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.24\n",
      "Global average valid RMSE: 0.24\n",
      "----------------------------------------\n",
      "Per-user average train RMSE: 0.22\n",
      "Per-user average valid RMSE: 0.23\n",
      "----------------------------------------\n",
      "Per-product average train RMSE: 0.22\n",
      "Per-product average valid RMSE: 0.23\n",
      "----------------------------------------\n",
      "Per-user and product average train RMSE: 0.21\n",
      "Per-user and product average valid RMSE: 0.22\n",
      "----------------------------------------\n",
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.24\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.20\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.22\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.17\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.22\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.15\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.22\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.11\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.23\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.04\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.23\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.00\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Making a copy for the stars column\n",
    "colab_train_s = colab_train.copy()\n",
    "colab_valid_s = colab_valid.copy()\n",
    "colab_train_s = colab_train_s.drop(['normalized_stars', 'popularity', 'activity_level'], axis=1)\n",
    "colab_valid_s = colab_valid_s.drop(['normalized_stars', 'popularity', 'activity_level'], axis=1)\n",
    "\n",
    "# Create utility matrix\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"stars\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "# Creating the utility matrix\n",
    "train_mat_s = create_Y_from_ratings(colab_train_s, N, M)\n",
    "valid_mat_s = create_Y_from_ratings(colab_valid_s, N, M)\n",
    "\n",
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "    # Calculate the range of Y1 (ignoring NaN values)\n",
    "    range_Y2 = np.nanmax(Y2) - np.nanmin(Y2)\n",
    "\n",
    "    # Calculate relative RMSE\n",
    "    relative_rmse = rmse / range_Y2 if range_Y2 != 0 else np.nan\n",
    "\n",
    "    return relative_rmse\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat_s, valid_mat_s, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat_s)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat_s)))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat_s)\n",
    "pred_g = np.zeros(train_mat_s.shape) + avg\n",
    "evaluate(pred_g, train_mat_s, valid_mat_s, model_name=\"Global average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat_s, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat_s, valid_mat_s, model_name=\"Per-user average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Calculate per-restaurant average baseline\n",
    "avg_m = np.nanmean(train_mat_s, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat_s, valid_mat_s, model_name=\"Per-product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat_s, valid_mat_s, model_name=\"Per-user and product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat_s)\n",
    "    evaluate(pred_knn, train_mat_s, valid_mat_s)\n",
    "\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Collaborative filtering with TruncatedSVD()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat_s - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat_s, valid_mat_s, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f4b7f-d404-4d92-81c9-46760c593e8e",
   "metadata": {},
   "source": [
    "## normalized_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "531001a2-01ae-4b91-9cf6-f85bf69a8a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.14\n",
      "Global average valid RMSE: 0.13\n",
      "----------------------------------------\n",
      "Per-user average train RMSE: 0.14\n",
      "Per-user average valid RMSE: 0.13\n",
      "----------------------------------------\n",
      "Per-product average train RMSE: 0.13\n",
      "Per-product average valid RMSE: 0.13\n",
      "----------------------------------------\n",
      "Per-user and product average train RMSE: 0.13\n",
      "Per-user and product average valid RMSE: 0.13\n",
      "----------------------------------------\n",
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.14\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.14\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.14\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.14\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.13\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.12\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.13\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.10\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.13\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.09\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.13\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.07\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.13\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.03\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.13\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.00\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Making a copy for the normalized_stars column\n",
    "colab_train_ns = colab_train.copy()\n",
    "colab_valid_ns = colab_valid.copy()\n",
    "colab_train_ns = colab_train_ns.drop(['stars', 'popularity', 'activity_level'], axis=1)\n",
    "colab_valid_ns = colab_valid_ns.drop(['stars', 'popularity', 'activity_level'], axis=1)\n",
    "\n",
    "# Create utility matrix\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"normalized_stars\"]\n",
    "\n",
    "    return Y\n",
    "    \n",
    "# Creating the utility matrix\n",
    "train_mat_ns = create_Y_from_ratings(colab_train_ns, N, M)\n",
    "valid_mat_ns = create_Y_from_ratings(colab_valid_ns, N, M)\n",
    "\n",
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "    # Calculate the range of Y1 (ignoring NaN values)\n",
    "    range_Y2 = np.nanmax(Y2) - np.nanmin(Y2)\n",
    "\n",
    "    # Calculate relative RMSE\n",
    "    relative_rmse = rmse / range_Y2 if range_Y2 != 0 else np.nan\n",
    "\n",
    "    return relative_rmse\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat_ns, valid_mat_ns, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat_ns)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat_ns)))\n",
    "\n",
    "\n",
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat_ns)\n",
    "pred_g = np.zeros(train_mat_ns.shape) + avg\n",
    "evaluate(pred_g, train_mat_ns, valid_mat_ns, model_name=\"Global average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat_ns, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat_ns, valid_mat_ns, model_name=\"Per-user average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Calculate per-restaurant average baseline\n",
    "avg_m = np.nanmean(train_mat_ns, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat_ns, valid_mat_ns, model_name=\"Per-product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat_ns, valid_mat_ns, model_name=\"Per-user and product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat_ns)\n",
    "    evaluate(pred_knn, train_mat_ns, valid_mat_ns)\n",
    "\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Collaborative filtering with TruncatedSVD()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat_ns - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat_ns, valid_mat_ns, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282848c-903f-4eab-8862-4493dceb105c",
   "metadata": {},
   "source": [
    "Now lets incorporate the `popularity` and `acitivity_level` features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e89f73-b35b-4c6f-b0de-a3b2752e5888",
   "metadata": {},
   "source": [
    "## normalized_stars * popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d4b2bff4-5c6d-43e4-af39-9bcfb0fdea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.06\n",
      "Global average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "Per-user average train RMSE: 0.06\n",
      "Per-user average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "Per-product average train RMSE: 0.06\n",
      "Per-product average valid RMSE: 0.05\n",
      "----------------------------------------\n",
      "Per-user and product average train RMSE: 0.06\n",
      "Per-user and product average valid RMSE: 0.05\n",
      "----------------------------------------\n",
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.05\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.05\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.04\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.03\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.02\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.01\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.00\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Making a copy for the popularity column\n",
    "colab_train_pop = colab_train.copy()\n",
    "colab_valid_pop = colab_valid.copy()\n",
    "colab_train_pop = colab_train_pop.drop(['stars', 'normalized_stars', 'activity_level'], axis=1)\n",
    "colab_valid_pop = colab_valid_pop.drop(['stars', 'normalized_stars', 'activity_level'], axis=1)\n",
    "\n",
    "# Create utility matrix\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"popularity\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "# Creating the utility matrix\n",
    "train_mat_pop = create_Y_from_ratings(colab_train_pop, N, M)\n",
    "valid_mat_pop = create_Y_from_ratings(colab_valid_pop, N, M)\n",
    "\n",
    "# Normalize modifier matrice popularity\n",
    "train_mat_pop = train_mat_pop / np.nanmax(train_mat_pop)\n",
    "valid_mat_pop = valid_mat_pop / np.nanmax(valid_mat_pop)\n",
    "\n",
    "# Apply modifiers to the main matrix with normalized_stars\n",
    "train_mat_ns_pop = train_mat_ns * train_mat_pop\n",
    "valid_mat_ns_pop = valid_mat_ns * valid_mat_pop\n",
    "\n",
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "    # Calculate the range of Y1 (ignoring NaN values)\n",
    "    range_Y2 = np.nanmax(Y2) - np.nanmin(Y2)\n",
    "\n",
    "    # Calculate relative RMSE\n",
    "    relative_rmse = rmse / range_Y2 if range_Y2 != 0 else np.nan\n",
    "\n",
    "    return relative_rmse\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat_ns_pop, valid_mat_ns_pop, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat_ns_pop)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat_ns_pop)))\n",
    "\n",
    "\n",
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat_ns_pop)\n",
    "pred_g = np.zeros(train_mat_ns_pop.shape) + avg\n",
    "evaluate(pred_g, train_mat_ns_pop, valid_mat_ns_pop, model_name=\"Global average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat_ns_pop, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat_ns_pop, valid_mat_ns_pop, model_name=\"Per-user average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Calculate per-restaurant average baseline\n",
    "avg_m = np.nanmean(train_mat_ns_pop, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat_ns_pop, valid_mat_ns_pop, model_name=\"Per-product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat_ns_pop, valid_mat_ns_pop, model_name=\"Per-user and product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat_ns_pop)\n",
    "    evaluate(pred_knn, train_mat_ns_pop, valid_mat_ns_pop)\n",
    "\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Collaborative filtering with TruncatedSVD()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat_ns_pop - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat_ns_pop, valid_mat_ns_pop, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481dcc8f-3f2d-4d94-9e7a-466dcfbaf6a9",
   "metadata": {},
   "source": [
    "## normalized_stars * activity_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "cbd2bdab-40c0-4737-983b-a4f4d9ad6d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 0.06\n",
      "Global average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "Per-user average train RMSE: 0.06\n",
      "Per-user average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "Per-product average train RMSE: 0.06\n",
      "Per-product average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "Per-user and product average train RMSE: 0.06\n",
      "Per-user and product average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 0.06\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.05\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.04\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.03\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.02\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.01\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.06\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.00\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Making a copy for the activity_level column\n",
    "colab_train_al = colab_train.copy()\n",
    "colab_valid_al = colab_valid.copy()\n",
    "colab_train_al = colab_train_al.drop(['stars', 'normalized_stars', 'popularity'], axis=1)\n",
    "colab_valid_al = colab_valid_al.drop(['stars', 'normalized_stars', 'popularity'], axis=1)\n",
    "\n",
    "# Create utility matrix\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"activity_level\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "# Creating the utility matrix\n",
    "train_mat_al = create_Y_from_ratings(colab_train_al, N, M)\n",
    "valid_mat_al = create_Y_from_ratings(colab_valid_al, N, M)\n",
    "\n",
    "# Normalize modifier matrice popularity\n",
    "train_mat_al = train_mat_al / np.nanmax(train_mat_al)\n",
    "valid_mat_al = valid_mat_al / np.nanmax(valid_mat_al)\n",
    "\n",
    "# Apply modifiers to the main matrix with normalized_stars\n",
    "train_mat_ns_al = train_mat_ns * train_mat_al\n",
    "valid_mat_ns_al = valid_mat_ns * valid_mat_al\n",
    "\n",
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "    # Calculate the range of Y1 (ignoring NaN values)\n",
    "    range_Y2 = np.nanmax(Y2) - np.nanmin(Y2)\n",
    "\n",
    "    # Calculate relative RMSE\n",
    "    relative_rmse = rmse / range_Y2 if range_Y2 != 0 else np.nan\n",
    "\n",
    "    return relative_rmse\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat_ns_ac, valid_mat_ns_al, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat_ns_al)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat_ns_al)))\n",
    "\n",
    "\n",
    "# Calculate global average rating baseline\n",
    "avg = np.nanmean(train_mat_ns_al)\n",
    "pred_g = np.zeros(train_mat_ns_al.shape) + avg\n",
    "evaluate(pred_g, train_mat_ns_al, valid_mat_ns_al, model_name=\"Global average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate per-user average baseline\n",
    "avg_n = np.nanmean(train_mat_ns_al, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat_ns_al, valid_mat_ns_al, model_name=\"Per-user average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Calculate per-restaurant average baseline\n",
    "avg_m = np.nanmean(train_mat_ns_al, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat_ns_al, valid_mat_ns_al, model_name=\"Per-product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# Calculate average of per-user and per-restaurant average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat_ns_al, valid_mat_ns_al, model_name=\"Per-user and product average\")\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat_ns_al)\n",
    "    evaluate(pred_knn, train_mat_ns_al, valid_mat_ns_al)\n",
    "\n",
    "\n",
    "print(\"-\" * 40)  # Prints a line of 40 dashes\n",
    "\n",
    "\n",
    "# Collaborative filtering with TruncatedSVD()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat_ns_al - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat_ns_al, valid_mat_ns_al, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc8e43-f8d3-47f4-b94e-305ae47839e8",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b8dc8-c6d6-4c0d-a40c-89782a5d7301",
   "metadata": {},
   "source": [
    "Looking at these results it looks like it would make sense to build the collaborative filtering model, using the `normalized_stars` along with either of the `popularity` or `activity_level` features as a multiplier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
